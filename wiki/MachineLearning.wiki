#summary Accord.MachineLearning namespace

 _This page is about the MachineLearning module of Accord.NET. For general descriptions on Machine Learning, please see [http://en.wikipedia.org/wiki/Machine_learning Machine learning (Wikipedia)]._


= Accord.MachineLearning =

The [http://accord.googlecode.com/svn/docs/html/N_Accord_MachineLearning.htm Accord.MachineLearning namespace] contains key classes for many machine learning algorithms and related tasks. One of the most prominent tools are the Support Vector Machines (SVMs), located in the [http://accord.googlecode.com/svn/docs/html/N_Accord_MachineLearning_VectorMachines.htm MachineLearning.VectorMachines namespace]. Other interesting applications are given by Decision Trees (DTs), clustering algorithms such as K-Means and meta-algorithms such as Cross-validation and RANSAC.

== Support Vector Machines ==

The Support Vector Machines are a popular class of machine learning methods, with many learning algorithms. The framework includes support for a variety of [http://accord.googlecode.com/svn/docs/html/N_Accord_Statistics_Kernels.htm kernel functions], including kernels suitable to be used with [http://accord.googlecode.com/svn/docs/html/N_Accord_Statistics_Kernels_Sparse.htm sparse data] in [http://www.csie.ntu.edu.tw/~cjlin/libsvm/ LibSVM's format] (LibSVM is a great SVM package, comparisons between Accord.NET and LibSVM are highly encouraged).

Accord.NET offers [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_VectorMachines_MulticlassSupportVectorMachine.htm multi-class] and [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_VectorMachines_MultilabelSupportVectorMachine.htm multi-label] SVMs. By definition, the SVM is only a binary classifier. To perform the classification of a sample among more than two classes it is necessary to consider a multiple class decision approach. The most common approaches are the one-vs-one and one-vs-all approaches. Another approach is given by Directed Acyclic Graphs (Platt, 1999). The framework [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_VectorMachines_MulticlassComputeMethod.htm offers all of them].

Sometimes there is also need to produce probabilistic results for the classifiers. The framework implements [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_VectorMachines_Learning_ProbabilisticOutputLearning.htm output calibration] (Platt, 2000; H.T. Lin, 2007) and is able to produce probabilistic outputs for any of the aforementioned classification approaches.

Moreover, the framework also offers the automatic determination of some learning parameters. For instance, the framework is able to determine [http://accord.googlecode.com/svn/docs/html/M_Accord_MachineLearning_VectorMachines_Learning_SequentialMinimalOptimization_EstimateComplexity.htm suitable values for C], for the [http://accord.googlecode.com/svn/docs/html/M_Accord_Statistics_Kernels_Gaussian_Estimate.htm Gaussian kernel's sigma] and [http://accord.googlecode.com/svn/docs/html/N_Accord_Statistics_Kernels.htm other kernels]. Those values are computed using heuristics detailed on the respective method documentations.

== Decision Trees ==

[http://accord.googlecode.com/svn/docs/html/N_Accord_MachineLearning_DecisionTrees.htm Decision Trees] are among the fastest to evaluate classifiers. The framework implements the [http://accord.googlecode.com/svn/docs/html/N_Accord_MachineLearning_DecisionTrees_Learning.htm ID3 and C4.5 algorithms] for learning decision trees, although learning is mostly limited to simple scenarios. However, the most useful feature of the framework is certainly the ability of generating machine code versions of Decision Trees on-the-fly, as detailed on the post [http://crsouza.blogspot.com.br/2012/01/decision-trees-in-c.html Decision Trees in C#]. 

== Naive Bayes ==

[http://accord.googlecode.com/svn/docs/html/N_Accord_MachineLearning_Bayes.htm Naive Bayes] classifiers are useful when there is apparent independence between input variables in a learning problem. The framework supports either [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_Bayes_NaiveBayes.htm discrete] or [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_Bayes_NaiveBayes_1.htm arbitrary density models] through the use of [http://en.wikipedia.org/wiki/Generic_programming Generics]. 

== Meta-algorithms ==

Meta-algorithms are algorithms designed to control other algorithms. For instance, consider the RANSAC algorithm, which can be used to create a robust version of any other classification algorithm; or the cross-validation algorithm, which is able to determine more statistically accurate performance estimates for any learning algorithm.

===RANdom SAmple Consensus (RANSAC)===

The [http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_RANSAC_1.htm RANdom SAmple Consensus (RANSAC)] algorithm can be used to turn virtually any algorithm in a robust algorithm. It works by learning nested models in different subsets of the data, hoping it will detect outliers (distinguishable data points which could have been the result of noise contamination or data acquisition error) in the process.

One of the most famous application of the RANSAC algorithm is to help detect inliers in homography estimation and image matching, such as demonstrated in the CodeProject article [http://www.codeproject.com/Articles/95453/Automatic-Image-Stitching-with-Accord-NET Automatic Image Stitching with Accord.NET]. A convenience class for achieving such results is available in the Accord.Imaging namespace: [http://accord.googlecode.com/svn/docs/html/T_Accord_Imaging_RansacHomographyEstimator.htm RansacHomographyEstimator].

=== Grid Search ===

[http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_GridSearch_1.htm Grid-Search] is a fancy name for selecting the best parameters of a model through a multivariate search. It can be used, for example, to determine the best C and sigma parameters in Gaussian-kernel SVM learning.

=== Cross-validation ===

[http://accord.googlecode.com/svn/docs/html/T_Accord_MachineLearning_CrossValidation_1.htm Cross-validation] is one of the basic methods for reliable performance assessment, absolutely useful when one have limited amounts of data and wish to obtain performance estimates for a given model.


<br />
----

 Please take a look on [http://accord.googlecode.com/svn/docs/Index.html the integral Accord.NET documentation] to get a more detailed overview of the available classes, methods and interfaces.