<html xmlns:MSHelp="http://msdn.microsoft.com/mshelp" xmlns:mshelp="http://msdn.microsoft.com/mshelp">
  <head>
    <link rel="SHORTCUT ICON" href="./../icons/favicon.ico" />
    <style type="text/css">.OH_CodeSnippetContainerTabLeftActive, .OH_CodeSnippetContainerTabLeft,.OH_CodeSnippetContainerTabLeftDisabled { backgroundImageName: tabLeftBG.gif; }.OH_CodeSnippetContainerTabRightActive, .OH_CodeSnippetContainerTabRight,.OH_CodeSnippetContainerTabRightDisabled { backgroundImageName: tabRightBG.gif; }.OH_footer { backgroundImageName: footer_slice.gif; background-position: top; background-repeat: repeat-x; }</style>
    <link rel="stylesheet" type="text/css" href="./../styles/branding.css" />
    <link rel="stylesheet" type="text/css" href="./../styles/branding-en-US.css" />
    <style type="text/css">
			body
			{
			border-left:5px solid #e6e6e6;
			overflow-x:scroll;
			overflow-y:scroll;
			}
		</style>
    <script src="./../scripts/branding.js" type="text/javascript">
      <!---->
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>BaumWelchLearning(TDistribution) Class</title>
    <meta name="Language" content="en-us" />
    <meta name="System.Keywords" content="BaumWelchLearning%3CTDistribution%3E class" />
    <meta name="System.Keywords" content="Accord.Statistics.Models.Markov.Learning.BaumWelchLearning%3CTDistribution%3E class" />
    <meta name="System.Keywords" content="BaumWelchLearning%3CTDistribution%3E class, about BaumWelchLearning%3CTDistribution%3E class" />
    <meta name="System.Keywords" content="BaumWelchLearning(Of TDistribution) class" />
    <meta name="System.Keywords" content="Accord.Statistics.Models.Markov.Learning.BaumWelchLearning(Of TDistribution) class" />
    <meta name="System.Keywords" content="BaumWelchLearning(Of TDistribution) class, about BaumWelchLearning(Of TDistribution) class" />
    <meta name="Microsoft.Help.F1" content="Accord.Statistics.Models.Markov.Learning.BaumWelchLearning`1" />
    <meta name="Microsoft.Help.Id" content="T:Accord.Statistics.Models.Markov.Learning.BaumWelchLearning`1" />
    <meta name="Description" content="Baum-Welch learning algorithm for arbitrary-density (generic) Hidden Markov Models." />
    <meta name="Microsoft.Help.ContentType" content="Reference" />
    <meta name="BrandingAware" content="'true'" />
    <meta name="container" content="Accord.Statistics.Models.Markov.Learning" />
    <meta name="file" content="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning_1" />
    <meta name="guid" content="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning_1" />
    
    <link type="text/css" rel="stylesheet" href="ms-help://Hx/HxRuntime/HxLink.css" />
    <link type="text/css" rel="stylesheet" href="./../styles/highlight.css" />
    <script type="text/javascript" src="../scripts/highlight.js">
      <!---->
    </script>
    <meta name="SelfBranded" content="true" />
  </head>
  <body onload="onLoad()" class="primary-mtps-offline-document">
    <div class="OH_outerDiv">
      <div class="OH_outerContent">
        <table class="TitleTable">
          <tr>
            <td class="OH_tdLogoColumn">
              <img alt="Accord.NET (logo)" src="./../icons/logo.png" />
            </td>
            <td class="OH_tdTitleColumn">BaumWelchLearning<span id="ID0EDBABAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EDBABAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script><span class="typeparameter">TDistribution</span><span id="ID0EBBABAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBBABAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script> Class</td>
            <td class="OH_tdRunningTitleColumn">Accord.NET Framework</td>
          </tr>
        </table>
        <div id="mainSection">
          <div id="mainBody">
            <span class="introStyle">
              <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" />
              <a href="http://accord-net.github.io/docs/Index.html" target="_top">Show table of contents (goes to the online documentation index).</a>
              <br />
            </span>
            <div class="summary">
               Baum-Welch learning algorithm for <a href="T_Accord_Statistics_Models_Markov_HiddenMarkovModel_1.htm" target="">
               arbitrary-density (generic) Hidden Markov Models</a>.
             </div>
            <div class="OH_CollapsibleAreaRegion">
              <div class="OH_regiontitle">Inheritance Hierarchy</div>
              <div class="OH_CollapsibleArea_HrDiv">
                <hr class="OH_CollapsibleArea_Hr" />
              </div>
            </div>
            <div class="OH_clear"></div>
            <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" />
            <a href="http://msdn2.microsoft.com/en-us/library/e5kfa45b" target="_blank">System<span id="ID0EBHOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBHOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>Object</a>
            <br />  <a href="T_Accord_Statistics_Models_Markov_Learning_BaseBaumWelchLearning.htm" target="">Accord.Statistics.Models.Markov.Learning<span id="ID0EBEOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBEOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaseBaumWelchLearning</a><br />    <span class="selflink">Accord.Statistics.Models.Markov.Learning<span id="ID0EEBOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EEBOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning<span id="ID0ECBOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0ECBOAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EABOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EABOAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script></span><br /><p></p><b>Namespace:</b> <a href="N_Accord_Statistics_Models_Markov_Learning.htm" target="">Accord.Statistics.Models.Markov.Learning</a><br /><b>Assembly:</b> <span sdata="assembly">Accord.Statistics</span> (in Accord.Statistics.dll) Version: 2.10.0.0 (2.10.0.4632)<div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Syntax</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><div id="snippetGroup_Syntax" class="code"><div id="ID0EABEAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EABEAAAAA_tabs"><div class="OH_CodeSnippetContainerTabLeftActive" id="ID0EABEAAAAA_tabimgleft"></div><div id="ID0EABEAAAAA_tab1" class="OH_CodeSnippetContainerTabActive" EnableCopyCode="true"><a href="#" onclick="javascript:ChangeTab('ID0EABEAAAAA','C#','1','4');return false;">C#</a></div><div id="ID0EABEAAAAA_tab2" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>VB</a></div><div id="ID0EABEAAAAA_tab3" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>C++</a></div><div id="ID0EABEAAAAA_tab4" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>F#</a></div><div class="OH_CodeSnippetContainerTabRight" id="ID0EABEAAAAA_tabimgright"></div></div><div id="ID0EABEAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EABEAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EABEAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EABEAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EABEAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EABEAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EABEAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EABEAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="keyword">public</span> <span class="keyword">class</span> <span class="identifier">BaumWelchLearning</span>&lt;TDistribution&gt; : <span class="identifier">BaseBaumWelchLearning</span>, 
	<span class="identifier">IUnsupervisedLearning</span>, <span class="identifier">IConvergenceLearning</span> 
<span class="keyword">where</span> TDistribution : <span class="identifier">IDistribution</span></pre></div><div id="ID0EABEAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>public class BaumWelchLearning&lt;TDistribution&gt; : BaseBaumWelchLearning, 
	IUnsupervisedLearning, IConvergenceLearning 
where TDistribution : IDistribution</pre></div><div id="ID0EABEAAAAA_code_Div2" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Plain_Div2" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Div3" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Plain_Div3" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Div4" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Plain_Div4" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div></div></div><script>addSpecificTextLanguageTagSet('ID0EABEAAAAA');</script></div><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Type Parameters</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><dl><dt><span class="parameter">TDistribution</span></dt><dd></dd></dl><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Remarks</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><p>
               The Baum-Welch algorithm is an <a href="T_Accord_Statistics_Models_Markov_Learning_IUnsupervisedLearning.htm" target="">unsupervised algorithm</a>
               used to learn a single hidden Markov model object from a set of observation sequences. It works
               by using a variant of the <a href="M_Accord_Statistics_Distributions_Univariate_Mixture_1_Fit_1.htm" target="">
               Expectation-Maximization</a> algorithm to search a set of model parameters (i.e. the matrix
               of <a href="P_Accord_Statistics_Models_Markov_IHiddenMarkovModel_Transitions.htm" target="">transition probabilities </a>, the vector of <a href="P_Accord_Statistics_Models_Markov_HiddenMarkovModel_1_Emissions.htm" target="">state probability distributions
               </a>, and the <a href="P_Accord_Statistics_Models_Markov_IHiddenMarkovModel_Probabilities.htm" target="">initial probability
               vector </a>) that would result in a model having a high likelihood of being able 
               to <a href="M_Accord_Statistics_Models_Markov_HiddenMarkovModel_1_Generate.htm" target="">generate</a> a set of training 
               sequences given to this algorithm.</p><p>
               For increased accuracy, this class performs all computations using log-probabilities.</p><p>
               For a more thorough explanation on <a href="T_Accord_Statistics_Models_Markov_HiddenMarkovModel.htm" target="">hidden Markov models</a>
               with practical examples on gesture recognition, please see 
               <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" /><a href="http://www.codeproject.com/Articles/541428/Sequence-Classifiers-in-Csharp-Part-I-Hidden-Marko" target="_blank">
               Sequence Classifiers in C#, Part I: Hidden Markov Models</a> [1].</p><p>
               [1]: <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" /><a href="http://www.codeproject.com/Articles/541428/Sequence-Classifiers-in-Csharp-Part-I-Hidden-Marko" target="_blank"> 
                       http://www.codeproject.com/Articles/541428/Sequence-Classifiers-in-Csharp-Part-I-Hidden-Marko </a></p><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Examples</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><p>
               In the following example, we will create a Continuous Hidden Markov Model using
               a univariate Normal distribution to model properly model continuous sequences.</p><div id="ID0ELCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0ELCAAAAA_tabs"></div><div id="ID0ELCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0ELCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0ELCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0ELCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0ELCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0ELCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0ELCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0ELCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Create continuous sequences. In the sequences below, there</span> 
<span class="highlight-comment">//  seems to be two states, one for values between 0 and 1 and</span> 
<span class="highlight-comment">//  another for values between 5 and 7. The states seems to be</span> 
<span class="highlight-comment">//  switched on every observation.</span> 
<span class="highlight-keyword">double</span>[][] sequences = <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] 
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">5.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.7</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">6.0</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0.2</span>, <span class="highlight-number">6.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.3</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">5.0</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">7.0</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">7.0</span>, <span class="highlight-number">0.2</span>, <span class="highlight-number">5.6</span> },
};


<span class="highlight-comment">// Specify a initial normal distribution for the samples.</span>
NormalDistribution density = <span class="highlight-keyword">new</span> NormalDistribution();

<span class="highlight-comment">// Creates a continuous hidden Markov Model with two states organized in a forward</span> 
<span class="highlight-comment">//  topology and an underlying univariate Normal distribution as probability density.</span> 
<span class="highlight-keyword">var</span> model = <span class="highlight-keyword">new</span> HiddenMarkovModel&lt;NormalDistribution&gt;(<span class="highlight-keyword">new</span> Ergodic(<span class="highlight-number">2</span>), density);

<span class="highlight-comment">// Configure the learning algorithms to train the sequence classifier until the</span> 
<span class="highlight-comment">// difference in the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;NormalDistribution&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,
};

<span class="highlight-comment">// Fit the model</span> 
<span class="highlight-keyword">double</span> likelihood = teacher.Run(sequences);

<span class="highlight-comment">// See the log-probability of the sequences learned</span> 
<span class="highlight-keyword">double</span> a1 = model.Evaluate(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">5.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.7</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">6.0</span> }); <span class="highlight-comment">// -0.12799388666109757</span> 
<span class="highlight-keyword">double</span> a2 = model.Evaluate(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">0.2</span>, <span class="highlight-number">6.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.3</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">5.0</span> }); <span class="highlight-comment">// 0.01171157434400194</span> 

<span class="highlight-comment">// See the log-probability of an unrelated sequence</span> 
<span class="highlight-keyword">double</span> a3 = model.Evaluate(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">1.1</span>, <span class="highlight-number">2.2</span>, <span class="highlight-number">1.3</span>, <span class="highlight-number">3.2</span>, <span class="highlight-number">4.2</span>, <span class="highlight-number">1.0</span> }); <span class="highlight-comment">// -298.7465244473417</span> 

<span class="highlight-comment">// We can transform the log-probabilities to actual probabilities:</span> 
<span class="highlight-keyword">double</span> likelihood = Math.Exp(logLikelihood);
a1 = Math.Exp(a1); <span class="highlight-comment">// 0.879</span>
a2 = Math.Exp(a2); <span class="highlight-comment">// 1.011</span>
a3 = Math.Exp(a3); <span class="highlight-comment">// 0.000</span> 

<span class="highlight-comment">// We can also ask the model to decode one of the sequences. After</span> 
<span class="highlight-comment">// this step the state variable will contain: { 0, 1, 0, 1, 0, 1 }</span> 

<span class="highlight-keyword">int</span>[] states = model.Decode(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">5.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.7</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">6.0</span> });</pre></div><div id="ID0ELCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Create continuous sequences. In the sequences below, there 
//  seems to be two states, one for values between 0 and 1 and 
//  another for values between 5 and 7. The states seems to be 
//  switched on every observation. 
double[][] sequences = new double[][] 
{
    new double[] { 0.1, 5.2, 0.3, 6.7, 0.1, 6.0 },
    new double[] { 0.2, 6.2, 0.3, 6.3, 0.1, 5.0 },
    new double[] { 0.1, 7.0, 0.1, 7.0, 0.2, 5.6 },
};


// Specify a initial normal distribution for the samples.
NormalDistribution density = new NormalDistribution();

// Creates a continuous hidden Markov Model with two states organized in a forward 
//  topology and an underlying univariate Normal distribution as probability density. 
var model = new HiddenMarkovModel&lt;NormalDistribution&gt;(new Ergodic(2), density);

// Configure the learning algorithms to train the sequence classifier until the 
// difference in the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;NormalDistribution&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,
};

// Fit the model 
double likelihood = teacher.Run(sequences);

// See the log-probability of the sequences learned 
double a1 = model.Evaluate(new[] { 0.1, 5.2, 0.3, 6.7, 0.1, 6.0 }); // -0.12799388666109757 
double a2 = model.Evaluate(new[] { 0.2, 6.2, 0.3, 6.3, 0.1, 5.0 }); // 0.01171157434400194 

// See the log-probability of an unrelated sequence 
double a3 = model.Evaluate(new[] { 1.1, 2.2, 1.3, 3.2, 4.2, 1.0 }); // -298.7465244473417 

// We can transform the log-probabilities to actual probabilities: 
double likelihood = Math.Exp(logLikelihood);
a1 = Math.Exp(a1); // 0.879
a2 = Math.Exp(a2); // 1.011
a3 = Math.Exp(a3); // 0.000 

// We can also ask the model to decode one of the sequences. After 
// this step the state variable will contain: { 0, 1, 0, 1, 0, 1 } 

int[] states = model.Decode(new[] { 0.1, 5.2, 0.3, 6.7, 0.1, 6.0 });</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0ELCAAAAA');</script><p>
               In the following example, we will create a Discrete Hidden Markov Model
               using a Generic Discrete Probability Distribution to reproduce the same
               code example given in  documentation.</p><div id="ID0EJCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EJCAAAAA_tabs"></div><div id="ID0EJCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EJCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EJCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EJCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EJCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EJCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EJCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EJCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Arbitrary-density Markov Models can operate using any</span> 
<span class="highlight-comment">// probability distribution, including discrete ones. </span> 

<span class="highlight-comment">// In the follwing example, we will try to create a</span> 
<span class="highlight-comment">// Discrete Hidden Markov Model using a discrete</span> 
<span class="highlight-comment">// distribution to detect if a given sequence starts</span> 
<span class="highlight-comment">// with a zero and has any number of ones after that.</span> 

<span class="highlight-keyword">double</span>[][] sequences = <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] 
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>         },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>       },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
};

<span class="highlight-comment">// Create a new Hidden Markov Model with 3 states and</span> 
<span class="highlight-comment">//  a generic discrete distribution with two symbols</span> 
<span class="highlight-keyword">var</span> hmm = <span class="highlight-keyword">new</span> HiddenMarkovModel.CreateGeneric(<span class="highlight-number">3</span>, <span class="highlight-number">2</span>);

<span class="highlight-comment">// We will try to fit the model to the data until the difference in</span> 
<span class="highlight-comment">//  the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;UniformDiscreteDistribution&gt;(hmm)
{ 
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span> 
};

<span class="highlight-comment">// Begin model training</span> 
<span class="highlight-keyword">double</span> ll = teacher.Run(sequences);


<span class="highlight-comment">// Calculate the likelihood that the given sequences originated</span> 
<span class="highlight-comment">// from the model. The commented values on the right are the </span> 
<span class="highlight-comment">// likelihoods computed by taking an exp(x) of the log-likelihoods</span> 
<span class="highlight-comment">// returned by the Evaluate method.</span> 
<span class="highlight-keyword">double</span> l1 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span> });       <span class="highlight-comment">// 0.999</span> 
<span class="highlight-keyword">double</span> l2 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span> }); <span class="highlight-comment">// 0.916</span> 

<span class="highlight-comment">// Sequences which do not start with zero have much lesser probability.</span> 
<span class="highlight-keyword">double</span> l3 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span> });       <span class="highlight-comment">// 0.000</span> 
<span class="highlight-keyword">double</span> l4 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span>, <span class="highlight-number">0</span>, <span class="highlight-number">0</span> }); <span class="highlight-comment">// 0.000</span> 

<span class="highlight-comment">// Sequences which contains few errors have higher probabability</span> 
<span class="highlight-comment">//  than the ones which do not start with zero. This shows some</span> 
<span class="highlight-comment">//  of the temporal elasticity and error tolerance of the HMMs.</span> 
<span class="highlight-keyword">double</span> l5 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span> }); <span class="highlight-comment">// 0.034</span> 
<span class="highlight-keyword">double</span> l6 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">0</span>, <span class="highlight-number">1</span> }); <span class="highlight-comment">// 0.034</span></pre></div><div id="ID0EJCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Arbitrary-density Markov Models can operate using any 
// probability distribution, including discrete ones.  

// In the follwing example, we will try to create a 
// Discrete Hidden Markov Model using a discrete 
// distribution to detect if a given sequence starts 
// with a zero and has any number of ones after that. 

double[][] sequences = new double[][] 
{
    new double[] { 0,1,1,1,1,0,1,1,1,1 },
    new double[] { 0,1,1,1,0,1,1,1,1,1 },
    new double[] { 0,1,1,1,1,1,1,1,1,1 },
    new double[] { 0,1,1,1,1,1         },
    new double[] { 0,1,1,1,1,1,1       },
    new double[] { 0,1,1,1,1,1,1,1,1,1 },
    new double[] { 0,1,1,1,1,1,1,1,1,1 },
};

// Create a new Hidden Markov Model with 3 states and 
//  a generic discrete distribution with two symbols 
var hmm = new HiddenMarkovModel.CreateGeneric(3, 2);

// We will try to fit the model to the data until the difference in 
//  the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;UniformDiscreteDistribution&gt;(hmm)
{ 
    Tolerance = 0.0001,
    Iterations = 0 
};

// Begin model training 
double ll = teacher.Run(sequences);


// Calculate the likelihood that the given sequences originated 
// from the model. The commented values on the right are the  
// likelihoods computed by taking an exp(x) of the log-likelihoods 
// returned by the Evaluate method. 
double l1 = hmm.Evaluate(new double[] { 0, 1 });       // 0.999 
double l2 = hmm.Evaluate(new double[] { 0, 1, 1, 1 }); // 0.916 

// Sequences which do not start with zero have much lesser probability. 
double l3 = hmm.Evaluate(new double[] { 1, 1 });       // 0.000 
double l4 = hmm.Evaluate(new double[] { 1, 0, 0, 0 }); // 0.000 

// Sequences which contains few errors have higher probabability 
//  than the ones which do not start with zero. This shows some 
//  of the temporal elasticity and error tolerance of the HMMs. 
double l5 = hmm.Evaluate(new double[] { 0, 1, 0, 1, 1, 1, 1, 1, 1 }); // 0.034 
double l6 = hmm.Evaluate(new double[] { 0, 1, 1, 1, 1, 1, 1, 0, 1 }); // 0.034</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EJCAAAAA');</script><p>
               The next example shows how to create a multivariate model using
               a multivariate normal distribution. In this example, sequences
               contain vector-valued observations, such as in the case of (x,y)
               pairs.</p><div id="ID0EHCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EHCAAAAA_tabs"></div><div id="ID0EHCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EHCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EHCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EHCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EHCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EHCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EHCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EHCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Create sequences of vector-valued observations. In the</span> 
<span class="highlight-comment">// sequence below, a single observation is composed of two</span> 
<span class="highlight-comment">// coordinate values, such as (x, y). There seems to be two</span> 
<span class="highlight-comment">// states, one for (x,y) values less than (5,5) and another</span> 
<span class="highlight-comment">// for higher values. The states seems to be switched on</span> 
<span class="highlight-comment">// every observation.</span> 
<span class="highlight-keyword">double</span>[][][] sequences =
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] <span class="highlight-comment">// sequence 1</span>
    {
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span> }, <span class="highlight-comment">// observation 1 of sequence 1</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">6</span>, <span class="highlight-number">7</span> }, <span class="highlight-comment">// observation 2 of sequence 1</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">3</span> }, <span class="highlight-comment">// observation 3 of sequence 1</span>
    },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] <span class="highlight-comment">// sequence 2</span>
    {
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">2</span> }, <span class="highlight-comment">// observation 1 of sequence 2</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">9</span>, <span class="highlight-number">8</span> }, <span class="highlight-comment">// observation 2 of sequence 2</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span> }, <span class="highlight-comment">// observation 3 of sequence 2</span>
    },
<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] <span class="highlight-comment">// sequence 3</span>
    {
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">3</span> }, <span class="highlight-comment">// observation 1 of sequence 3</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">8</span>, <span class="highlight-number">9</span> }, <span class="highlight-comment">// observation 2 of sequence 3</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">3</span>, <span class="highlight-number">3</span> }, <span class="highlight-comment">// observation 3 of sequence 3</span>
    },
};


<span class="highlight-comment">// Specify a initial normal distribution for the samples.</span> 
<span class="highlight-keyword">var</span> density = <span class="highlight-keyword">new</span> MultivariateNormalDistribution(dimension: <span class="highlight-number">2</span>);

<span class="highlight-comment">// Creates a continuous hidden Markov Model with two states organized in a forward</span> 
<span class="highlight-comment">//  topology and an underlying univariate Normal distribution as probability density.</span> 
<span class="highlight-keyword">var</span> model = <span class="highlight-keyword">new</span> HiddenMarkovModel&lt;MultivariateNormalDistribution&gt;(<span class="highlight-keyword">new</span> Forward(<span class="highlight-number">2</span>), density);

<span class="highlight-comment">// Configure the learning algorithms to train the sequence classifier until the</span> 
<span class="highlight-comment">// difference in the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;MultivariateNormalDistribution&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,
};

<span class="highlight-comment">// Fit the model</span> 
<span class="highlight-keyword">double</span> logLikelihood = teacher.Run(sequences);

<span class="highlight-comment">// See the likelihood of the sequences learned</span> 
<span class="highlight-keyword">double</span> a1 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> [] { 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span> }, 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">6</span>, <span class="highlight-number">7</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">3</span> }})); <span class="highlight-comment">// 0.000208</span> 

<span class="highlight-keyword">double</span> a2 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> [] { 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">2</span> }, 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">9</span>, <span class="highlight-number">8</span>  },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span> }})); <span class="highlight-comment">// 0.0000376</span> 

<span class="highlight-comment">// See the likelihood of an unrelated sequence</span> 
<span class="highlight-keyword">double</span> a3 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> [] { 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">8</span>, <span class="highlight-number">7</span> }, 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">9</span>, <span class="highlight-number">8</span>  },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span> }})); <span class="highlight-comment">// 2.10 x 10^(-89)</span></pre></div><div id="ID0EHCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Create sequences of vector-valued observations. In the 
// sequence below, a single observation is composed of two 
// coordinate values, such as (x, y). There seems to be two 
// states, one for (x,y) values less than (5,5) and another 
// for higher values. The states seems to be switched on 
// every observation. 
double[][][] sequences =
{
    new double[][] // sequence 1
    {
        new double[] { 1, 2 }, // observation 1 of sequence 1 
        new double[] { 6, 7 }, // observation 2 of sequence 1 
        new double[] { 2, 3 }, // observation 3 of sequence 1
    },
    new double[][] // sequence 2
    {
        new double[] { 2, 2 }, // observation 1 of sequence 2 
        new double[] { 9, 8 }, // observation 2 of sequence 2 
        new double[] { 1, 0 }, // observation 3 of sequence 2
    },
new double[][] // sequence 3
    {
        new double[] { 1, 3 }, // observation 1 of sequence 3 
        new double[] { 8, 9 }, // observation 2 of sequence 3 
        new double[] { 3, 3 }, // observation 3 of sequence 3
    },
};


// Specify a initial normal distribution for the samples. 
var density = new MultivariateNormalDistribution(dimension: 2);

// Creates a continuous hidden Markov Model with two states organized in a forward 
//  topology and an underlying univariate Normal distribution as probability density. 
var model = new HiddenMarkovModel&lt;MultivariateNormalDistribution&gt;(new Forward(2), density);

// Configure the learning algorithms to train the sequence classifier until the 
// difference in the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;MultivariateNormalDistribution&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,
};

// Fit the model 
double logLikelihood = teacher.Run(sequences);

// See the likelihood of the sequences learned 
double a1 = Math.Exp(model.Evaluate(new [] { 
    new double[] { 1, 2 }, 
    new double[] { 6, 7 },
    new double[] { 2, 3 }})); // 0.000208 

double a2 = Math.Exp(model.Evaluate(new [] { 
    new double[] { 2, 2 }, 
    new double[] { 9, 8  },
    new double[] { 1, 0 }})); // 0.0000376 

// See the likelihood of an unrelated sequence 
double a3 = Math.Exp(model.Evaluate(new [] { 
    new double[] { 8, 7 }, 
    new double[] { 9, 8  },
    new double[] { 1, 0 }})); // 2.10 x 10^(-89)</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EHCAAAAA');</script><p>
               Finally, the last example shows how to fit a mixture-density
               hidden Markov models.
             </p><div id="ID0EFCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EFCAAAAA_tabs"></div><div id="ID0EFCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EFCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EFCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EFCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EFCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EFCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EFCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EFCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Suppose we have a set of six sequences and we would like to</span> 
<span class="highlight-comment">// fit a hidden Markov model with mixtures of Normal distributions</span> 
<span class="highlight-comment">// as the emission densities. </span> 

<span class="highlight-comment">// First, let's consider a set of univariate sequences:</span> 
<span class="highlight-keyword">double</span>[][] sequences =
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">5</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">4</span>, <span class="highlight-number">5</span>, <span class="highlight-number">5</span>, <span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">5</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">4</span>, <span class="highlight-number">4</span>, <span class="highlight-number">5</span> },
};


<span class="highlight-comment">// Now we can begin specifing a initial Gaussian mixture distribution. It is</span> 
<span class="highlight-comment">// better to add some different initial parameters to the mixture components:</span> 
<span class="highlight-keyword">var</span> density = <span class="highlight-keyword">new</span> Mixture&lt;NormalDistribution&gt;(
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">2</span>, stdDev: <span class="highlight-number">1.0</span>), <span class="highlight-comment">// 1st component in the mixture</span> 
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">0</span>, stdDev: <span class="highlight-number">0.6</span>), <span class="highlight-comment">// 2nd component in the mixture</span> 
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">4</span>, stdDev: <span class="highlight-number">0.4</span>), <span class="highlight-comment">// 3rd component in the mixture</span> 
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">6</span>, stdDev: <span class="highlight-number">1.1</span>)  <span class="highlight-comment">// 4th component in the mixture</span>
);

<span class="highlight-comment">// Let's then create a continuous hidden Markov Model with two states organized in a forward</span> 
<span class="highlight-comment">//  topology with the underlying univariate Normal mixture distribution as probability density.</span> 
<span class="highlight-keyword">var</span> model = <span class="highlight-keyword">new</span> HiddenMarkovModel&lt;Mixture&lt;NormalDistribution&gt;&gt;(<span class="highlight-keyword">new</span> Forward(<span class="highlight-number">2</span>), density);

<span class="highlight-comment">// Now we should configure the learning algorithms to train the sequence classifier. We will</span> 
<span class="highlight-comment">// learn until the difference in the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;Mixture&lt;NormalDistribution&gt;&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,

    <span class="highlight-comment">// Note, however, that since this example is extremely simple and we have only a few</span> 
    <span class="highlight-comment">// data points, a full-blown mixture wouldn't really be needed. Thus we will have a</span> 
    <span class="highlight-comment">// great chance that the mixture would become degenerated quickly. We can avoid this</span> 
    <span class="highlight-comment">// by specifying some regularization constants in the Normal distribution fitting:</span>

    FittingOptions = <span class="highlight-keyword">new</span> MixtureOptions()
    {
        Iterations = <span class="highlight-number">1</span>, <span class="highlight-comment">// limit the inner e-m to a single iteration</span>

        InnerOptions = <span class="highlight-keyword">new</span> NormalOptions()
        {
            Regularization = <span class="highlight-number">1</span>e<span class="highlight-number">-5</span> <span class="highlight-comment">// specify a regularization constant</span> 

            <span class="highlight-comment">// Please note that specifying a regularization constant avoids getting the exception</span> 
            <span class="highlight-comment">// "Variance is zero. Try specifying a regularization constant in the fitting options."</span>
        }
    }
};

<span class="highlight-comment">// Finally, we can fit the model</span> 
<span class="highlight-keyword">double</span> logLikelihood = teacher.Run(sequences);

<span class="highlight-comment">// And now check the likelihood of some approximate sequences.</span> 
<span class="highlight-keyword">double</span> a1 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span> })); <span class="highlight-comment">// 2.3413833128741038E+45</span> 
<span class="highlight-keyword">double</span> a2 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">5</span>, <span class="highlight-number">5</span> })); <span class="highlight-comment">// 9.94607618459872E+19</span> 

<span class="highlight-comment">// We can see that the likelihood of an unrelated sequence is much smaller:</span> 
<span class="highlight-keyword">double</span> a3 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">8</span>, <span class="highlight-number">2</span>, <span class="highlight-number">6</span>, <span class="highlight-number">4</span>, <span class="highlight-number">1</span> })); <span class="highlight-comment">// 1.5063654166181737E-44</span></pre></div><div id="ID0EFCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Suppose we have a set of six sequences and we would like to 
// fit a hidden Markov model with mixtures of Normal distributions 
// as the emission densities.  

// First, let's consider a set of univariate sequences: 
double[][] sequences =
{
    new double[] { 1, 1, 2, 2, 2, 3, 3, 3 },
    new double[] { 1, 2, 2, 2, 3, 3 },
    new double[] { 1, 2, 2, 3, 3, 5 },
    new double[] { 2, 2, 2, 2, 3, 3, 3, 4, 5, 5, 1 },
    new double[] { 1, 1, 1, 2, 2, 5 },
    new double[] { 1, 2, 2, 4, 4, 5 },
};


// Now we can begin specifing a initial Gaussian mixture distribution. It is 
// better to add some different initial parameters to the mixture components: 
var density = new Mixture&lt;NormalDistribution&gt;(
    new NormalDistribution(mean: 2, stdDev: 1.0), // 1st component in the mixture 
    new NormalDistribution(mean: 0, stdDev: 0.6), // 2nd component in the mixture 
    new NormalDistribution(mean: 4, stdDev: 0.4), // 3rd component in the mixture 
    new NormalDistribution(mean: 6, stdDev: 1.1)  // 4th component in the mixture
);

// Let's then create a continuous hidden Markov Model with two states organized in a forward 
//  topology with the underlying univariate Normal mixture distribution as probability density. 
var model = new HiddenMarkovModel&lt;Mixture&lt;NormalDistribution&gt;&gt;(new Forward(2), density);

// Now we should configure the learning algorithms to train the sequence classifier. We will 
// learn until the difference in the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;Mixture&lt;NormalDistribution&gt;&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,

    // Note, however, that since this example is extremely simple and we have only a few 
    // data points, a full-blown mixture wouldn't really be needed. Thus we will have a 
    // great chance that the mixture would become degenerated quickly. We can avoid this 
    // by specifying some regularization constants in the Normal distribution fitting:

    FittingOptions = new MixtureOptions()
    {
        Iterations = 1, // limit the inner e-m to a single iteration

        InnerOptions = new NormalOptions()
        {
            Regularization = 1e-5 // specify a regularization constant 

            // Please note that specifying a regularization constant avoids getting the exception 
            // "Variance is zero. Try specifying a regularization constant in the fitting options."
        }
    }
};

// Finally, we can fit the model 
double logLikelihood = teacher.Run(sequences);

// And now check the likelihood of some approximate sequences. 
double a1 = Math.Exp(model.Evaluate(new double[] { 1, 1, 2, 2, 3 })); // 2.3413833128741038E+45 
double a2 = Math.Exp(model.Evaluate(new double[] { 1, 1, 2, 5, 5 })); // 9.94607618459872E+19 

// We can see that the likelihood of an unrelated sequence is much smaller: 
double a3 = Math.Exp(model.Evaluate(new double[] { 8, 2, 6, 4, 1 })); // 1.5063654166181737E-44</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EFCAAAAA');</script><p>
               When using Normal distributions, it is often the case we might find problems
               which are difficult to solve. Some problems may include constant variables or
               other numerical difficulties preventing a the proper estimation of a Normal 
               distribution from the data. </p><p> 
               A sign of those difficulties arises when the learning algorithm throws the exception
               <span class="code">"Variance is zero. Try specifying a regularization constant in the fitting options"</span> 
               for univariate distributions (e.g. <a href="T_Accord_Statistics_Distributions_Univariate_NormalDistribution.htm" target="">NormalDistribution</a> or a <a href="T_Accord_NonPositiveDefiniteMatrixException.htm" target="">NonPositiveDefiniteMatrixException</a> informing that the <span class="code">"Covariance matrix
               is not positive definite. Try specifying a regularization constant in the fitting options"</span>
               for multivariate distributions like the <a href="T_Accord_Statistics_Distributions_Multivariate_MultivariateNormalDistribution.htm" target="">MultivariateNormalDistribution</a>.
               In both cases, this is an indication that the variables being learned can not be suitably 
               modeled by Normal distributions. To avoid numerical difficulties when estimating those
               probabilities, a small regularization constant can be added to the variances or to the
               covariance matrices until they become greater than zero or positive definite.</p><p>
               To specify a regularization constant as given in the above message, we 
               can indicate a fitting options object for the model distribution using:
             </p><div id="ID0EBCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EBCAAAAA_tabs"></div><div id="ID0EBCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EBCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EBCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EBCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EBCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EBCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EBCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EBCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;NormalDistribution&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,

    FittingOptions = <span class="highlight-keyword">new</span> NormalOptions()
    {
        Regularization = <span class="highlight-number">1</span>e<span class="highlight-number">-5</span> <span class="highlight-comment">// specify a regularization constant</span>
    }
};</pre></div><div id="ID0EBCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>var teacher = new BaumWelchLearning&lt;NormalDistribution&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,

    FittingOptions = new NormalOptions()
    {
        Regularization = 1e-5 // specify a regularization constant
    }
};</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EBCAAAAA');</script><p>
               Typically, any small value would suffice as a regularization constant,
               though smaller values may lead to longer fitting times. Too high values,
               on the other hand, would lead to decreased accuracy.</p><a name="seeAlsoSection"><!----></a><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">See Also</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><div class="seeAlsoStyle"><a href="AllMembers_T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning_1.htm" target="">BaumWelchLearning<span id="ID0EDAGAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EDAGAAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EBAGAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBAGAAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script> Members</a></div><div class="seeAlsoStyle"><a href="N_Accord_Statistics_Models_Markov_Learning.htm" target="">Accord.Statistics.Models.Markov.Learning Namespace</a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning.htm" target="">Accord.Statistics.Models.Markov.Learning<span id="ID0EBAEAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBAEAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning</a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_HiddenMarkovModel.htm" target="">Accord.Statistics.Models.Markov<span id="ID0EBADAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBADAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>HiddenMarkovModel</a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_HiddenMarkovModel_1.htm" target="">Accord.Statistics.Models.Markov<span id="ID0EEACAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EEACAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>HiddenMarkovModel<span id="ID0ECACAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0ECACAAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EAACAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EAACAAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script></a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning.htm" target="">Accord.Statistics.Models.Markov.Learning<span id="ID0EBABAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBABAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning</a></div><div class="seeAlsoStyle"><span class="selflink">Accord.Statistics.Models.Markov.Learning<span id="ID0EEAAAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EEAAAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning<span id="ID0ECAAAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0ECAAAAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EAAAAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EAAAAAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script></span></div></div>
        </div>
      </div>
    </div>
    <div id="OH_footer" class="OH_footer">
      <p>
        <a href="http://accord-net.github.io/" target="_blank">Accord.NET Framework</a> © 2009-2013. All documentation is licensed under the Creative Commons Attribution/Share-Alike License.</p>
      <div class="OH_feedbacklink">
        <a href="mailto:?subject=Accord.NET+Framework+BaumWelchLearning(TDistribution)+Class+100+EN-US&amp;body=Your%20feedback%20is%20used%20to%20improve%20the%20documentation%20and%20the%20product.%20Your%20e-mail%20address%20will%20not%20be%20used%20for%20any%20other%20purpose%20and%20is%20disposed%20of%20after%20the%20issue%20you%20report%20is%20resolved.%20While%20working%20to%20resolve%20the%20issue%20that%20you%20report%2c%20you%20may%20be%20contacted%20via%20e-mail%20to%20get%20further%20details%20or%20clarification%20on%20the%20feedback%20you%20sent.%20After%20the%20issue%20you%20report%20has%20been%20addressed%2c%20you%20may%20receive%20an%20e-mail%20to%20let%20you%20know%20that%20your%20feedback%20has%20been%20addressed.">Send Feedback</a> on this topic.</div>
    </div>
  </body>
</html>