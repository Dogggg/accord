<html xmlns:MSHelp="http://msdn.microsoft.com/mshelp" xmlns:mshelp="http://msdn.microsoft.com/mshelp">
  <head>
    <link rel="SHORTCUT ICON" href="./../icons/favicon.ico" />
    <style type="text/css">.OH_CodeSnippetContainerTabLeftActive, .OH_CodeSnippetContainerTabLeft,.OH_CodeSnippetContainerTabLeftDisabled { backgroundImageName: tabLeftBG.gif; }.OH_CodeSnippetContainerTabRightActive, .OH_CodeSnippetContainerTabRight,.OH_CodeSnippetContainerTabRightDisabled { backgroundImageName: tabRightBG.gif; }.OH_footer { backgroundImageName: footer_slice.gif; background-position: top; background-repeat: repeat-x; }</style>
    <link rel="stylesheet" type="text/css" href="./../styles/branding.css" />
    <link rel="stylesheet" type="text/css" href="./../styles/branding-en-US.css" />
    <style type="text/css">
			body
			{
			border-left:5px solid #e6e6e6;
			overflow-x:scroll;
			overflow-y:scroll;
			}
		</style>
    <script src="./../scripts/branding.js" type="text/javascript">
      <!---->
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>BaumWelchLearning(TDistribution) Class</title>
    <meta name="Language" content="en-us" />
    <meta name="System.Keywords" content="BaumWelchLearning%3CTDistribution%3E class" />
    <meta name="System.Keywords" content="Accord.Statistics.Models.Markov.Learning.BaumWelchLearning%3CTDistribution%3E class" />
    <meta name="System.Keywords" content="BaumWelchLearning%3CTDistribution%3E class, about BaumWelchLearning%3CTDistribution%3E class" />
    <meta name="System.Keywords" content="BaumWelchLearning(Of TDistribution) class" />
    <meta name="System.Keywords" content="Accord.Statistics.Models.Markov.Learning.BaumWelchLearning(Of TDistribution) class" />
    <meta name="System.Keywords" content="BaumWelchLearning(Of TDistribution) class, about BaumWelchLearning(Of TDistribution) class" />
    <meta name="Microsoft.Help.F1" content="Accord.Statistics.Models.Markov.Learning.BaumWelchLearning`1" />
    <meta name="Microsoft.Help.Id" content="T:Accord.Statistics.Models.Markov.Learning.BaumWelchLearning`1" />
    <meta name="Description" content="Baum-Welch learning algorithm for arbitrary-density Hidden Markov Models." />
    <meta name="Microsoft.Help.ContentType" content="Reference" />
    <meta name="BrandingAware" content="'true'" />
    <meta name="container" content="Accord.Statistics.Models.Markov.Learning" />
    <meta name="file" content="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning_1" />
    <meta name="guid" content="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning_1" />
    
    <link type="text/css" rel="stylesheet" href="./../styles/highlight.css" />
    <script type="text/javascript" src="../scripts/highlight.js">
      <!---->
    </script>
    <meta name="SelfBranded" content="true" />
  </head>
  <body onload="onLoad()" class="primary-mtps-offline-document">
    <div class="OH_outerDiv">
      <div class="OH_outerContent">
        <table class="TitleTable">
          <tr>
            <td class="OH_tdLogoColumn">
              <img alt="Accord.NET (logo)" src="./../icons/logo.png" />
            </td>
            <td class="OH_tdTitleColumn">BaumWelchLearning<span id="ID0EDBABAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EDBABAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script><span class="typeparameter">TDistribution</span><span id="ID0EBBABAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBBABAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script> Class</td>
            <td class="OH_tdRunningTitleColumn">Accord.NET Framework</td>
          </tr>
        </table>
        <div id="mainSection">
          <div id="mainBody">
            <span class="introStyle">
              <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" />
              <a href="http://accord.googlecode.com/svn/docs/Index.html" target="_top">Show table of contents (goes to the online documentation index).</a>
              <br />
            </span>
            <div class="summary">
              Baum-Welch learning algorithm for arbitrary-density Hidden Markov Models.
            </div>
            <div class="OH_CollapsibleAreaRegion">
              <div class="OH_regiontitle">Inheritance Hierarchy</div>
              <div class="OH_CollapsibleArea_HrDiv">
                <hr class="OH_CollapsibleArea_Hr" />
              </div>
            </div>
            <div class="OH_clear"></div>
            <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" />
            <a href="http://msdn2.microsoft.com/en-us/library/e5kfa45b" target="_blank">System<span id="ID0EBHOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBHOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>Object</a>
            <br />  <a href="T_Accord_Statistics_Models_Markov_Learning_BaseBaumWelchLearning.htm" target="">Accord.Statistics.Models.Markov.Learning<span id="ID0EBEOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBEOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaseBaumWelchLearning</a><br />    <span class="selflink">Accord.Statistics.Models.Markov.Learning<span id="ID0EEBOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EEBOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning<span id="ID0ECBOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0ECBOAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EABOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EABOAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script></span><br /><p></p><b>Namespace:</b> <a href="N_Accord_Statistics_Models_Markov_Learning.htm" target="">Accord.Statistics.Models.Markov.Learning</a><br /><b>Assembly:</b> <span sdata="assembly">Accord.Statistics</span> (in Accord.Statistics.dll) Version: 2.9.0.0 (2.9.0.0)<div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Syntax</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><div id="snippetGroup_Syntax" class="code"><div id="ID0EABEAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EABEAAAAA_tabs"><div class="OH_CodeSnippetContainerTabLeftActive" id="ID0EABEAAAAA_tabimgleft"></div><div id="ID0EABEAAAAA_tab1" class="OH_CodeSnippetContainerTabActive" EnableCopyCode="true"><a href="#" onclick="javascript:ChangeTab('ID0EABEAAAAA','C#','1','4');return false;">C#</a></div><div id="ID0EABEAAAAA_tab2" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>VB</a></div><div id="ID0EABEAAAAA_tab3" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>C++</a></div><div id="ID0EABEAAAAA_tab4" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>F#</a></div><div class="OH_CodeSnippetContainerTabRight" id="ID0EABEAAAAA_tabimgright"></div></div><div id="ID0EABEAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EABEAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EABEAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EABEAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EABEAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EABEAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EABEAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EABEAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="keyword">public</span> <span class="keyword">class</span> <span class="identifier">BaumWelchLearning</span>&lt;TDistribution&gt; : <a href="T_Accord_Statistics_Models_Markov_Learning_BaseBaumWelchLearning.htm">BaseBaumWelchLearning</a>, 
	<a href="T_Accord_Statistics_Models_Markov_Learning_IUnsupervisedLearning.htm">IUnsupervisedLearning</a>, <a href="T_Accord_Statistics_Models_IConvergenceLearning.htm">IConvergenceLearning</a> 
<span class="keyword">where</span> TDistribution : <a href="T_Accord_Statistics_Distributions_IDistribution.htm">IDistribution</a></pre></div><div id="ID0EABEAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>public class BaumWelchLearning&lt;TDistribution&gt; : BaseBaumWelchLearning, 
	IUnsupervisedLearning, IConvergenceLearning 
where TDistribution : IDistribution</pre></div><div id="ID0EABEAAAAA_code_Div2" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Plain_Div2" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Div3" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Plain_Div3" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Div4" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EABEAAAAA_code_Plain_Div4" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div></div></div><script>addSpecificTextLanguageTagSet('ID0EABEAAAAA');</script></div><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Type Parameters</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><dl><dt><span class="parameter">TDistribution</span></dt><dd></dd></dl><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Remarks</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><p>
              The Baum-Welch algorithm is a kind of Expectation-Maximization algorithm.
              For continuous models, it estimates the matrix of state transition probabilities
              A and the vector of initial state probabilities pi. For the state emission 
              densities, it weights each observation and lets the estimation algorithms
              for each of the densities to fit the distributions to the observations.</p><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Examples</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><p>
              In the following example, we will create a Continuous Hidden Markov Model using
              a univariate Normal distribution to model properly model continuous sequences.</p><div id="ID0EGCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EGCAAAAA_tabs"></div><div id="ID0EGCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EGCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EGCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EGCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EGCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EGCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EGCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EGCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Create continuous sequences. In the sequences below, there</span> 
<span class="highlight-comment">//  seems to be two states, one for values between 0 and 1 and</span> 
<span class="highlight-comment">//  another for values between 5 and 7. The states seems to be</span> 
<span class="highlight-comment">//  switched on every observation.</span> 
<span class="highlight-keyword">double</span>[][] sequences = <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] 
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">5.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.7</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">6.0</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0.2</span>, <span class="highlight-number">6.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.3</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">5.0</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">7.0</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">7.0</span>, <span class="highlight-number">0.2</span>, <span class="highlight-number">5.6</span> },
};


<span class="highlight-comment">// Specify a initial normal distribution for the samples.</span>
NormalDistribution density = NormalDistribution();

<span class="highlight-comment">// Creates a continuous hidden Markov Model with two states organized in a forward</span> 
<span class="highlight-comment">//  topology and an underlying univariate Normal distribution as probability density.</span> 
<span class="highlight-keyword">var</span> model = <span class="highlight-keyword">new</span> HiddenMarkovModel&lt;NormalDistribution&gt;(<span class="highlight-keyword">new</span> Ergodic(<span class="highlight-number">2</span>), density);

<span class="highlight-comment">// Configure the learning algorithms to train the sequence classifier until the</span> 
<span class="highlight-comment">// difference in the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;NormalDistribution&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,
};

<span class="highlight-comment">// Fit the model</span> 
<span class="highlight-keyword">double</span> likelihood = teacher.Run(sequences);

<span class="highlight-comment">// See the likelihood of the sequences learned</span> 
<span class="highlight-keyword">double</span> l1 = model.Evaluate(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">0.1</span>, <span class="highlight-number">5.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.7</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">6.0</span> }); <span class="highlight-comment">// 0.87</span> 
<span class="highlight-keyword">double</span> l2 = model.Evaluate(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">0.2</span>, <span class="highlight-number">6.2</span>, <span class="highlight-number">0.3</span>, <span class="highlight-number">6.3</span>, <span class="highlight-number">0.1</span>, <span class="highlight-number">5.0</span> }); <span class="highlight-comment">// 1.00</span> 

<span class="highlight-comment">// See the probability of an unrelated sequence</span> 
<span class="highlight-keyword">double</span> l3 = model.Evaluate(<span class="highlight-keyword">new</span>[] { <span class="highlight-number">1.1</span>, <span class="highlight-number">2.2</span>, <span class="highlight-number">1.3</span>, <span class="highlight-number">3.2</span>, <span class="highlight-number">4.2</span>, <span class="highlight-number">1.0</span> }); <span class="highlight-comment">// 0.00</span></pre></div><div id="ID0EGCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Create continuous sequences. In the sequences below, there 
//  seems to be two states, one for values between 0 and 1 and 
//  another for values between 5 and 7. The states seems to be 
//  switched on every observation. 
double[][] sequences = new double[][] 
{
    new double[] { 0.1, 5.2, 0.3, 6.7, 0.1, 6.0 },
    new double[] { 0.2, 6.2, 0.3, 6.3, 0.1, 5.0 },
    new double[] { 0.1, 7.0, 0.1, 7.0, 0.2, 5.6 },
};


// Specify a initial normal distribution for the samples.
NormalDistribution density = NormalDistribution();

// Creates a continuous hidden Markov Model with two states organized in a forward 
//  topology and an underlying univariate Normal distribution as probability density. 
var model = new HiddenMarkovModel&lt;NormalDistribution&gt;(new Ergodic(2), density);

// Configure the learning algorithms to train the sequence classifier until the 
// difference in the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;NormalDistribution&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,
};

// Fit the model 
double likelihood = teacher.Run(sequences);

// See the likelihood of the sequences learned 
double l1 = model.Evaluate(new[] { 0.1, 5.2, 0.3, 6.7, 0.1, 6.0 }); // 0.87 
double l2 = model.Evaluate(new[] { 0.2, 6.2, 0.3, 6.3, 0.1, 5.0 }); // 1.00 

// See the probability of an unrelated sequence 
double l3 = model.Evaluate(new[] { 1.1, 2.2, 1.3, 3.2, 4.2, 1.0 }); // 0.00</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EGCAAAAA');</script><p>
              In the following example, we will create a Discrete Hidden Markov Model
              using a Generic Discrete Probability Distribution to reproduce the same
              code example given in  documentation.</p><div id="ID0EECAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EECAAAAA_tabs"></div><div id="ID0EECAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EECAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EECAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EECAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EECAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EECAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EECAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EECAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Arbitrary-density Markov Models can operate using any</span> 
<span class="highlight-comment">// probability distribution, including discrete ones. </span> 

<span class="highlight-comment">// In the follwing example, we will try to create a</span> 
<span class="highlight-comment">// Discrete Hidden Markov Model using a discrete</span> 
<span class="highlight-comment">// distribution to detect if a given sequence starts</span> 
<span class="highlight-comment">// with a zero and has any number of ones after that.</span> 

<span class="highlight-keyword">double</span>[][] sequences = <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] 
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>         },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>       },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span>,<span class="highlight-number">1</span> },
};

<span class="highlight-comment">// Create a new Hidden Markov Model with 3 states and</span> 
<span class="highlight-comment">//  a generic discrete distribution with two symbols</span> 
<span class="highlight-keyword">var</span> hmm = <span class="highlight-keyword">new</span> HiddenMarkovModel.CreateGeneric(<span class="highlight-number">3</span>, <span class="highlight-number">2</span>);

<span class="highlight-comment">// We will try to fit the model to the data until the difference in</span> 
<span class="highlight-comment">//  the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;UniformDiscreteDistribution&gt;(hmm)
{ 
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span> 
};

<span class="highlight-comment">// Begin model training</span> 
<span class="highlight-keyword">double</span> ll = teacher.Run(sequences);


<span class="highlight-comment">// Calculate the likelihood that the given sequences originated</span> 
<span class="highlight-comment">// from the model. The commented values on the right are the </span> 
<span class="highlight-comment">// likelihoods computed by taking an exp(x) of the log-likelihoods</span> 
<span class="highlight-comment">// returned by the Evaluate method.</span> 
<span class="highlight-keyword">double</span> l1 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span> });       <span class="highlight-comment">// 0.999</span> 
<span class="highlight-keyword">double</span> l2 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span> }); <span class="highlight-comment">// 0.916</span> 

<span class="highlight-comment">// Sequences which do not start with zero have much lesser probability.</span> 
<span class="highlight-keyword">double</span> l3 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span> });       <span class="highlight-comment">// 0.000</span> 
<span class="highlight-keyword">double</span> l4 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span>, <span class="highlight-number">0</span>, <span class="highlight-number">0</span> }); <span class="highlight-comment">// 0.000</span> 

<span class="highlight-comment">// Sequences which contains few errors have higher probabability</span> 
<span class="highlight-comment">//  than the ones which do not start with zero. This shows some</span> 
<span class="highlight-comment">//  of the temporal elasticity and error tolerance of the HMMs.</span> 
<span class="highlight-keyword">double</span> l5 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span> }); <span class="highlight-comment">// 0.034</span> 
<span class="highlight-keyword">double</span> l6 = hmm.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">0</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">0</span>, <span class="highlight-number">1</span> }); <span class="highlight-comment">// 0.034</span></pre></div><div id="ID0EECAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Arbitrary-density Markov Models can operate using any 
// probability distribution, including discrete ones.  

// In the follwing example, we will try to create a 
// Discrete Hidden Markov Model using a discrete 
// distribution to detect if a given sequence starts 
// with a zero and has any number of ones after that. 

double[][] sequences = new double[][] 
{
    new double[] { 0,1,1,1,1,0,1,1,1,1 },
    new double[] { 0,1,1,1,0,1,1,1,1,1 },
    new double[] { 0,1,1,1,1,1,1,1,1,1 },
    new double[] { 0,1,1,1,1,1         },
    new double[] { 0,1,1,1,1,1,1       },
    new double[] { 0,1,1,1,1,1,1,1,1,1 },
    new double[] { 0,1,1,1,1,1,1,1,1,1 },
};

// Create a new Hidden Markov Model with 3 states and 
//  a generic discrete distribution with two symbols 
var hmm = new HiddenMarkovModel.CreateGeneric(3, 2);

// We will try to fit the model to the data until the difference in 
//  the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;UniformDiscreteDistribution&gt;(hmm)
{ 
    Tolerance = 0.0001,
    Iterations = 0 
};

// Begin model training 
double ll = teacher.Run(sequences);


// Calculate the likelihood that the given sequences originated 
// from the model. The commented values on the right are the  
// likelihoods computed by taking an exp(x) of the log-likelihoods 
// returned by the Evaluate method. 
double l1 = hmm.Evaluate(new double[] { 0, 1 });       // 0.999 
double l2 = hmm.Evaluate(new double[] { 0, 1, 1, 1 }); // 0.916 

// Sequences which do not start with zero have much lesser probability. 
double l3 = hmm.Evaluate(new double[] { 1, 1 });       // 0.000 
double l4 = hmm.Evaluate(new double[] { 1, 0, 0, 0 }); // 0.000 

// Sequences which contains few errors have higher probabability 
//  than the ones which do not start with zero. This shows some 
//  of the temporal elasticity and error tolerance of the HMMs. 
double l5 = hmm.Evaluate(new double[] { 0, 1, 0, 1, 1, 1, 1, 1, 1 }); // 0.034 
double l6 = hmm.Evaluate(new double[] { 0, 1, 1, 1, 1, 1, 1, 0, 1 }); // 0.034</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EECAAAAA');</script><p>
              The next example shows how to create a multivariate model using
              a multivariate normal distribution. In this example, sequences
              contain vector-valued observations, such as in the case of (x,y)
              pairs.</p><div id="ID0ECCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0ECCAAAAA_tabs"></div><div id="ID0ECCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0ECCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0ECCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0ECCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0ECCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0ECCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0ECCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0ECCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Create sequences of vector-valued observations. In the</span> 
<span class="highlight-comment">// sequence below, a single observation is composed of two</span> 
<span class="highlight-comment">// coordinate values, such as (x, y). There seems to be two</span> 
<span class="highlight-comment">// states, one for (x,y) values less than (5,5) and another</span> 
<span class="highlight-comment">// for higher values. The states seems to be switched on</span> 
<span class="highlight-comment">// every observation.</span> 
<span class="highlight-keyword">double</span>[][][] sequences =
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] <span class="highlight-comment">// sequence 1</span>
    {
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span> }, <span class="highlight-comment">// observation 1 of sequence 1</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">6</span>, <span class="highlight-number">7</span> }, <span class="highlight-comment">// observation 2 of sequence 1</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">3</span> }, <span class="highlight-comment">// observation 3 of sequence 1</span>
    },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] <span class="highlight-comment">// sequence 2</span>
    {
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">2</span> }, <span class="highlight-comment">// observation 1 of sequence 2</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">9</span>, <span class="highlight-number">8</span> }, <span class="highlight-comment">// observation 2 of sequence 2</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span> }, <span class="highlight-comment">// observation 3 of sequence 2</span>
    },
<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[][] <span class="highlight-comment">// sequence 3</span>
    {
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">3</span> }, <span class="highlight-comment">// observation 1 of sequence 3</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">8</span>, <span class="highlight-number">9</span> }, <span class="highlight-comment">// observation 2 of sequence 3</span> 
        <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">3</span>, <span class="highlight-number">3</span> }, <span class="highlight-comment">// observation 3 of sequence 3</span>
    },
};


<span class="highlight-comment">// Specify a initial normal distribution for the samples.</span> 
<span class="highlight-keyword">var</span> density = <span class="highlight-keyword">new</span> MultivariateNormalDistribution(dimension: <span class="highlight-number">2</span>);

<span class="highlight-comment">// Creates a continuous hidden Markov Model with two states organized in a forward</span> 
<span class="highlight-comment">//  topology and an underlying univariate Normal distribution as probability density.</span> 
<span class="highlight-keyword">var</span> model = <span class="highlight-keyword">new</span> HiddenMarkovModel&lt;MultivariateNormalDistribution&gt;(<span class="highlight-keyword">new</span> Forward(<span class="highlight-number">2</span>), density);

<span class="highlight-comment">// Configure the learning algorithms to train the sequence classifier until the</span> 
<span class="highlight-comment">// difference in the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;MultivariateNormalDistribution&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,
};

<span class="highlight-comment">// Fit the model</span> 
<span class="highlight-keyword">double</span> logLikelihood = teacher.Run(sequences);

<span class="highlight-comment">// See the likelihood of the sequences learned</span> 
<span class="highlight-keyword">double</span> a1 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> [] { 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span> }, 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">6</span>, <span class="highlight-number">7</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">3</span> }})); <span class="highlight-comment">// 0.000208</span> 

<span class="highlight-keyword">double</span> a2 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> [] { 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">2</span> }, 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">9</span>, <span class="highlight-number">8</span>  },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span> }})); <span class="highlight-comment">// 0.0000376</span> 

<span class="highlight-comment">// See the likelihood of an unrelated sequence</span> 
<span class="highlight-keyword">double</span> a3 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> [] { 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">8</span>, <span class="highlight-number">7</span> }, 
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">9</span>, <span class="highlight-number">8</span>  },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">0</span> }})); <span class="highlight-comment">// 2.10 x 10^(-89)</span></pre></div><div id="ID0ECCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Create sequences of vector-valued observations. In the 
// sequence below, a single observation is composed of two 
// coordinate values, such as (x, y). There seems to be two 
// states, one for (x,y) values less than (5,5) and another 
// for higher values. The states seems to be switched on 
// every observation. 
double[][][] sequences =
{
    new double[][] // sequence 1
    {
        new double[] { 1, 2 }, // observation 1 of sequence 1 
        new double[] { 6, 7 }, // observation 2 of sequence 1 
        new double[] { 2, 3 }, // observation 3 of sequence 1
    },
    new double[][] // sequence 2
    {
        new double[] { 2, 2 }, // observation 1 of sequence 2 
        new double[] { 9, 8 }, // observation 2 of sequence 2 
        new double[] { 1, 0 }, // observation 3 of sequence 2
    },
new double[][] // sequence 3
    {
        new double[] { 1, 3 }, // observation 1 of sequence 3 
        new double[] { 8, 9 }, // observation 2 of sequence 3 
        new double[] { 3, 3 }, // observation 3 of sequence 3
    },
};


// Specify a initial normal distribution for the samples. 
var density = new MultivariateNormalDistribution(dimension: 2);

// Creates a continuous hidden Markov Model with two states organized in a forward 
//  topology and an underlying univariate Normal distribution as probability density. 
var model = new HiddenMarkovModel&lt;MultivariateNormalDistribution&gt;(new Forward(2), density);

// Configure the learning algorithms to train the sequence classifier until the 
// difference in the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;MultivariateNormalDistribution&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,
};

// Fit the model 
double logLikelihood = teacher.Run(sequences);

// See the likelihood of the sequences learned 
double a1 = Math.Exp(model.Evaluate(new [] { 
    new double[] { 1, 2 }, 
    new double[] { 6, 7 },
    new double[] { 2, 3 }})); // 0.000208 

double a2 = Math.Exp(model.Evaluate(new [] { 
    new double[] { 2, 2 }, 
    new double[] { 9, 8  },
    new double[] { 1, 0 }})); // 0.0000376 

// See the likelihood of an unrelated sequence 
double a3 = Math.Exp(model.Evaluate(new [] { 
    new double[] { 8, 7 }, 
    new double[] { 9, 8  },
    new double[] { 1, 0 }})); // 2.10 x 10^(-89)</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0ECCAAAAA');</script><p>
              Finally, the last example shows how to fit a mixture-density
              hidden Markov models.
            </p><div id="ID0EACAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EACAAAAA_tabs"></div><div id="ID0EACAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EACAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EACAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EACAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EACAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EACAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EACAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EACAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Suppose we have a set of six sequences and we would like to</span> 
<span class="highlight-comment">// fit a hidden Markov model with mixtures of Normal distributions</span> 
<span class="highlight-comment">// as the emission densities. </span> 

<span class="highlight-comment">// First, let's consider a set of univariate sequences:</span> 
<span class="highlight-keyword">double</span>[][] sequences =
{
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">5</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">3</span>, <span class="highlight-number">4</span>, <span class="highlight-number">5</span>, <span class="highlight-number">5</span>, <span class="highlight-number">1</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">5</span> },
    <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">4</span>, <span class="highlight-number">4</span>, <span class="highlight-number">5</span> },
};


<span class="highlight-comment">// Now we can begin specifing a initial Gaussian mixture distribution. It is</span> 
<span class="highlight-comment">// better to add some different initial parameters to the mixture components:</span> 
<span class="highlight-keyword">var</span> density = <span class="highlight-keyword">new</span> Mixture&lt;NormalDistribution&gt;(
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">2</span>, stdDev: <span class="highlight-number">1.0</span>), <span class="highlight-comment">// 1st component in the mixture</span> 
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">0</span>, stdDev: <span class="highlight-number">0.6</span>), <span class="highlight-comment">// 2nd component in the mixture</span> 
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">4</span>, stdDev: <span class="highlight-number">0.4</span>), <span class="highlight-comment">// 3rd component in the mixture</span> 
    <span class="highlight-keyword">new</span> NormalDistribution(mean: <span class="highlight-number">6</span>, stdDev: <span class="highlight-number">1.1</span>)  <span class="highlight-comment">// 4th component in the mixture</span>
);

<span class="highlight-comment">// Let's then create a continuous hidden Markov Model with two states organized in a forward</span> 
<span class="highlight-comment">//  topology with the underlying univariate Normal mixture distribution as probability density.</span> 
<span class="highlight-keyword">var</span> model = <span class="highlight-keyword">new</span> HiddenMarkovModel&lt;Mixture&lt;NormalDistribution&gt;&gt;(<span class="highlight-keyword">new</span> Forward(<span class="highlight-number">2</span>), density);

<span class="highlight-comment">// Now we should configure the learning algorithms to train the sequence classifier. We will</span> 
<span class="highlight-comment">// learn until the difference in the average log-likelihood changes only by as little as 0.0001</span> 
<span class="highlight-keyword">var</span> teacher = <span class="highlight-keyword">new</span> BaumWelchLearning&lt;Mixture&lt;NormalDistribution&gt;&gt;(model)
{
    Tolerance = <span class="highlight-number">0.0001</span>,
    Iterations = <span class="highlight-number">0</span>,

    <span class="highlight-comment">// Note, however, that since this example is extremely simple and we have only a few</span> 
    <span class="highlight-comment">// data points, a full-blown mixture wouldn't really be needed. Thus we will have a</span> 
    <span class="highlight-comment">// great chance that the mixture would become degenerated quickly. We can avoid this</span> 
    <span class="highlight-comment">// by specifying some regularization constants in the Normal distribution fitting:</span>

    FittingOptions = <span class="highlight-keyword">new</span> MixtureOptions()
    {
        Iterations = <span class="highlight-number">1</span>, <span class="highlight-comment">// limit the inner e-m to a single iteration</span>

        InnerOptions = <span class="highlight-keyword">new</span> NormalOptions()
        {
            Regularization = <span class="highlight-number">1</span>e<span class="highlight-number">-5</span> <span class="highlight-comment">// specify a regularization constant</span>
        }
    }
};

<span class="highlight-comment">// Finally, we can fit the model</span> 
<span class="highlight-keyword">double</span> logLikelihood = teacher.Run(sequences);

<span class="highlight-comment">// And now check the likelihood of some approximate sequences.</span> 
<span class="highlight-keyword">double</span> a1 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">2</span>, <span class="highlight-number">3</span> })); <span class="highlight-comment">// 2.3413833128741038E+45</span> 
<span class="highlight-keyword">double</span> a2 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">1</span>, <span class="highlight-number">1</span>, <span class="highlight-number">2</span>, <span class="highlight-number">5</span>, <span class="highlight-number">5</span> })); <span class="highlight-comment">// 9.94607618459872E+19</span> 

<span class="highlight-comment">// We can see that the likelihood of an unrelated sequence is much smaller:</span> 
<span class="highlight-keyword">double</span> a3 = Math.Exp(model.Evaluate(<span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[] { <span class="highlight-number">8</span>, <span class="highlight-number">2</span>, <span class="highlight-number">6</span>, <span class="highlight-number">4</span>, <span class="highlight-number">1</span> })); <span class="highlight-comment">// 1.5063654166181737E-44</span></pre></div><div id="ID0EACAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Suppose we have a set of six sequences and we would like to 
// fit a hidden Markov model with mixtures of Normal distributions 
// as the emission densities.  

// First, let's consider a set of univariate sequences: 
double[][] sequences =
{
    new double[] { 1, 1, 2, 2, 2, 3, 3, 3 },
    new double[] { 1, 2, 2, 2, 3, 3 },
    new double[] { 1, 2, 2, 3, 3, 5 },
    new double[] { 2, 2, 2, 2, 3, 3, 3, 4, 5, 5, 1 },
    new double[] { 1, 1, 1, 2, 2, 5 },
    new double[] { 1, 2, 2, 4, 4, 5 },
};


// Now we can begin specifing a initial Gaussian mixture distribution. It is 
// better to add some different initial parameters to the mixture components: 
var density = new Mixture&lt;NormalDistribution&gt;(
    new NormalDistribution(mean: 2, stdDev: 1.0), // 1st component in the mixture 
    new NormalDistribution(mean: 0, stdDev: 0.6), // 2nd component in the mixture 
    new NormalDistribution(mean: 4, stdDev: 0.4), // 3rd component in the mixture 
    new NormalDistribution(mean: 6, stdDev: 1.1)  // 4th component in the mixture
);

// Let's then create a continuous hidden Markov Model with two states organized in a forward 
//  topology with the underlying univariate Normal mixture distribution as probability density. 
var model = new HiddenMarkovModel&lt;Mixture&lt;NormalDistribution&gt;&gt;(new Forward(2), density);

// Now we should configure the learning algorithms to train the sequence classifier. We will 
// learn until the difference in the average log-likelihood changes only by as little as 0.0001 
var teacher = new BaumWelchLearning&lt;Mixture&lt;NormalDistribution&gt;&gt;(model)
{
    Tolerance = 0.0001,
    Iterations = 0,

    // Note, however, that since this example is extremely simple and we have only a few 
    // data points, a full-blown mixture wouldn't really be needed. Thus we will have a 
    // great chance that the mixture would become degenerated quickly. We can avoid this 
    // by specifying some regularization constants in the Normal distribution fitting:

    FittingOptions = new MixtureOptions()
    {
        Iterations = 1, // limit the inner e-m to a single iteration

        InnerOptions = new NormalOptions()
        {
            Regularization = 1e-5 // specify a regularization constant
        }
    }
};

// Finally, we can fit the model 
double logLikelihood = teacher.Run(sequences);

// And now check the likelihood of some approximate sequences. 
double a1 = Math.Exp(model.Evaluate(new double[] { 1, 1, 2, 2, 3 })); // 2.3413833128741038E+45 
double a2 = Math.Exp(model.Evaluate(new double[] { 1, 1, 2, 5, 5 })); // 9.94607618459872E+19 

// We can see that the likelihood of an unrelated sequence is much smaller: 
double a3 = Math.Exp(model.Evaluate(new double[] { 8, 2, 6, 4, 1 })); // 1.5063654166181737E-44</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EACAAAAA');</script><a name="seeAlsoSection"><!----></a><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">See Also</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><div class="seeAlsoStyle"><a href="AllMembers_T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning_1.htm" target="">BaumWelchLearning<span id="ID0EDAGAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EDAGAAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EBAGAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBAGAAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script> Members</a></div><div class="seeAlsoStyle"><a href="N_Accord_Statistics_Models_Markov_Learning.htm" target="">Accord.Statistics.Models.Markov.Learning Namespace</a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning.htm" target="">Accord.Statistics.Models.Markov.Learning<span id="ID0EBAEAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBAEAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning</a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_HiddenMarkovModel.htm" target="">Accord.Statistics.Models.Markov<span id="ID0EBADAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBADAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>HiddenMarkovModel</a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_HiddenMarkovModel_1.htm" target="">Accord.Statistics.Models.Markov<span id="ID0EEACAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EEACAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>HiddenMarkovModel<span id="ID0ECACAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0ECACAAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EAACAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EAACAAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script></a></div><div class="seeAlsoStyle"><a href="T_Accord_Statistics_Models_Markov_Learning_BaumWelchLearning.htm" target="">Accord.Statistics.Models.Markov.Learning<span id="ID0EBABAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBABAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning</a></div><div class="seeAlsoStyle"><span class="selflink">Accord.Statistics.Models.Markov.Learning<span id="ID0EEAAAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EEAAAAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>BaumWelchLearning<span id="ID0ECAAAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0ECAAAAAAAA?vb=(Of |cpp=&lt;|cs=&lt;|fs=&lt;'|nu=(");
				</script>TDistribution<span id="ID0EAAAAAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EAAAAAAAAA?vb=)|cpp=&gt;|cs=&gt;|fs=&gt;|nu=)");
				</script></span></div></div>
        </div>
      </div>
    </div>
    <div id="OH_footer" class="OH_footer">
      <p>
        <a href="http://accord.googlecode.com" target="_blank">Accord.NET Framework</a> © 2009-2013. All documentation is licensed under the Creative Commons Attribution/Share-Alike License.</p>
      <div class="OH_feedbacklink">
        <a href="mailto:?subject=Accord.NET+Framework+BaumWelchLearning(TDistribution)+Class+100+EN-US&amp;body=Your%20feedback%20is%20used%20to%20improve%20the%20documentation%20and%20the%20product.%20Your%20e-mail%20address%20will%20not%20be%20used%20for%20any%20other%20purpose%20and%20is%20disposed%20of%20after%20the%20issue%20you%20report%20is%20resolved.%20While%20working%20to%20resolve%20the%20issue%20that%20you%20report%2c%20you%20may%20be%20contacted%20via%20e-mail%20to%20get%20further%20details%20or%20clarification%20on%20the%20feedback%20you%20sent.%20After%20the%20issue%20you%20report%20has%20been%20addressed%2c%20you%20may%20receive%20an%20e-mail%20to%20let%20you%20know%20that%20your%20feedback%20has%20been%20addressed.">Send Feedback</a> on this topic.</div>
    </div>
  </body>
</html>